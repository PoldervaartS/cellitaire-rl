{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097718a2-6084-47c3-bff5-0cb825914fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from cellitaire.environment.agents.ppo_agent.agent import Agent, AgentConfig\n",
    "from cellitaire.environment.cellitaire_env import CellitaireEnv, CellitaireEnvConfig\n",
    "from cellitaire.environment.rewards.reward import *\n",
    "from cellitaire.environment.rewards.foundation_rewards import *\n",
    "\n",
    "normalize_reward = False\n",
    "\n",
    "steps_per_learn_step = 10000\n",
    "\n",
    "checkpoint_dir = 'tmp/experiment_1'\n",
    "\n",
    "board_rows = 7\n",
    "board_cols = 12\n",
    "\n",
    "test_reward = CombinedReward([\n",
    "    WinReward(weight=100, rows=board_rows, cols=board_cols),\n",
    "    ScalingPlacedCardInFoundationReward(weight=1, rows=board_rows, cols=board_cols),\n",
    "])\n",
    "\n",
    "\n",
    "env = CellitaireEnv(\n",
    "    reward = test_reward,\n",
    "    config_dir = checkpoint_dir\n",
    ")\n",
    "\n",
    "n_actions = env.action_space.n,\n",
    "input_dims = (board_rows * board_cols * 4 + 6,)\n",
    "\n",
    "agent = Agent(\n",
    "    n_actions = n_actions,\n",
    "    input_dims = input_dims,\n",
    "    config_dir=checkpoint_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6376cf-2810-46e6-a200-9c0ba512d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New run, godspeed lad\n"
     ]
    }
   ],
   "source": [
    "from cellitaire.environment.agents.ppo_agent.trainer import AgentTrainer\n",
    "\n",
    "trainer = AgentTrainer(\n",
    "    agent = agent,\n",
    "    env = env,\n",
    "    checkpoint_dir = checkpoint_dir,\n",
    "    steps_per_learn_step = steps_per_learn_step,\n",
    "    batch_size = agent.config.batch_size,\n",
    "    normalize_reward = normalize_reward\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ba5e5-442c-47f4-a45f-7136433f2468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Episode     100: R Avg Score  114.1 | R Max Score 1176 | R Avg CS  8.3 | R Max CS 48 | LS     1\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43852fd9-0ee1-4fb4-b63a-7fa432c1fa99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
